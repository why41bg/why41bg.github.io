---
title: 页表的机理及实现
date: 2023-10-30 11:52:14
tags:
- OS
- XV6
---
> 本篇文章以xv6为基础，记录在学习操作系统过程中对页表及其实现机制的理解。操作系统需要在应用程序与应用程序之间、应用程序和内核程序之间提供强隔离性。而页表就提供了一种这样的强隔离性。

# 基础概念介绍

页（page）：**内存管理是以页为单位的**，4096（$2^{12}$，4K，这个大小几乎适用于所有的处理器）字节为一页。所以物理内存是以4096为粒度使用的。一个页在物理内存当中是连续的，不同页在物理内存当中可以是离散的。

# 地址转换过程

对于任何一条带地址的指令，其中的地址应该认为是虚拟内存地址，而不是物理地址。虚拟内存地址仅对其隶属的进程可见，一个进程看不见其它进程的虚拟地址，这就在应用程序之间提供了强隔离性。一条带虚拟地址的指令结果如下图：

![带地址指令结构](/images/带地址指令.png)

CPU在执行一条执行时，首先会将虚拟内存地址发送给内存管理单元（MMU，Memory Management Unit），内存管理单元会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。从CPU的角度来说，一旦MMU打开了，它执行的每条指令中的地址都是虚拟内存地址。

这些虚拟地址到物理地址的映射关系是保存在一张表单中的，暂且将这张表称为地址转换表，这张表也是存放于内存中的。RISC-V中有一个叫做**SATP的寄存器**，这个寄存器就保存了地址转化表在物理内存当中的地址。CPU会将SATP寄存器中的值发送给MMU，MMU就根据这个物理地址找到地址转换表，从而将指令中的虚拟地址转换成物理地址。值得注意的是，MMU在这里做的仅仅只是读取这个表单，然后完成地址转换工作，它并不会保存这个表单（SATP寄存器由内核管理，写SATP寄存器是一条特殊权限指令，这很好理解吧）。

SATP寄存器中保存的地址是物理地址还是虚拟地址呢？答案是物理地址，因为MMU需要根据这个地址找到地址转换表，如果SATP中存放的是虚拟地址，那么还需要另外一种硬件负责将实际的地址转化表的存储位置找到，这就导致一直递归下去了。因此，**SATP寄存器**当中存放的一定是物理地址。

# 页表

到目前位置，这个地址转换表还不能称之为页表，因为它的每一个表项仅仅只是记录了一个虚拟地址到一个物理地址的映射关系。由于这个地址转化表存在于内存当中，如果按照这种记录方式，那么光是存储这个表，就会占满我们的内存，这显然是不可取的。因此，实际情况并不会为每个地址创建一个表项，而是为每一个**page**创建一条表项。采用这种方式后，地址翻译方式就产生了略微变化。在RISC-V中，寄存器有64位，对于一条64位带地址指令来说，前25位是操作码，后面39位是地址码。地址码又分为前27位index，后12位offset（页内偏移）。

![带地址指令结构](/images/带地址指令.png)

地址翻译流程大概为，首先MMU根据SATP寄存器中的地址找到地址转换表，然后根据index找到对应的表项，根据表项中记录的地址（此时为物理地址）在内存中找到对应的物理页，再根据offset找到对应页中的具体的某一字节。这里只需要大概理解地址翻译流程，而不必深究其细节，因为实际情况和这个还是存在一些不同。现在，可以将这个地址转换表称之为页表了。但是，如果采用这种方法建立页表，光是在内存中存储页表还是会导致内存占满。因此，在RISC-V中，实际情况是采用的3级页表。index的前面9位为L2级页表的索引号，中间9位为L1级页表的索引号，最后9位为L0级页表的索引号。

在RISC-V中，物理地址是54位的（64位最高位的10位保留剩下，剩下54位），其中44bit是物理page号（PPN，Physical Page Number），剩下12bit是offset。下面这段话引用自Frans教授和他学生的对话。

>Student：因为这是一个64bit的机器，为什么硬件设计人员本可以用64bit但是却用了56bit？
>
>Frans教授：选择56bit而不是64bit是因为在主板上只需要56根线。

一个页表的大小和页的大小是一样的，为4KB，一个页表项为64位（因为RISC-V中寄存器是64位），即8B。因此，一个页表有 $2^{12} \div 2^{3} = 2^{9}$ 这么多个表项，每一个表项称之为PTE（Page Table Entry），这也解释了为什么每级页表的索引号都只需要9个bit位。下面来描述一下实际情况中，逻辑地址是如何映射到物理地址的。

首先MMU根据SATP寄存器中的值，找到最高一级的页表，这里这个页表只有512个表项（PET），根据index的高9位找到对应的表项，取出其中的64位。这里有一点值得注意，PET的索引号并没有在表中写出来，而是隐含着的，例如第一项的索引号为0，第二项的索引号为1。这时候取出的64为就是L1级页表所在的物理地址，然后根据index中间9位找到L1级页表对应的PET，找到L0级页表，即最后一级页表。根据index最后9位找到L0级页表当中的PET，这时找到的物理地址就指明了物理内存当中的某一页，直接加上offset即可对应的具体的字节。到此，整个逻辑地址到物理地址的翻译就完成了。

![三级页表翻译流程](/images/三级页表翻译流程.png)

从某种程度上来说，3级索引和1级索引是很相似的。3级索引的主要优点是，如果地址空间中大部分地址都没有使用，不必为每一个index准备一个条目。举个例子，如果地址空间只使用了一个 page，4096Bytes。除此之外，没有使用任何其他的地址。那么一共需要多少个PET或者说 Page Table 来映射这个 page 呢？如果使用3级索引，在最高级需要一个页表，中间级需要一个页表，最低一级也需要一个页表，那么一共是 $3 × 512$ 个条目。如果采用1级索引，需要 $2^{27}$ 个条目。采用3级索引所需的空间大大减少了。这是实际上硬件采用这种层次化的3级page directory结构的主要原因。

在地址翻译流程图中可以看到，每个PET占64位，只有中间44位指明了一个物理内存地址，最高的10位是保留位，以便将来扩展使用，最低10是标志位。

1. 第一个标志位是Valid。如果Valid bit位为1，那么表明这是一条合法的PTE，你可以用它来做地址翻译。
2. 下两个标志位分别是Readable和Writable。表明你是否可以读/写这个page。
3. Executable表明你可以从这个page执行指令。
4. User表明这个page可以被运行在用户空间的进程访问。
5. 其他标志位并不是那么重要，他们偶尔会出现，前面5个是重要的标志位。

# 页表缓存（Translation Lookaside Buffer）

当MMU在做地址转换工作的时候，由于采用的是3级页表，所以需要3次读取内存，这里所花费的代价是有点大的。所以实际中，几乎所有的处理器都会对于最近使用过的虚拟地址的翻译结果有缓存。这个缓存被称为：Translation Lookside Buffer（常翻译为页表缓存），缩写为TLB。基本上来说，这就是Page Table Entry的缓存，也就是PTE的缓存。这样下一次当你访问同一个虚拟地址时，处理器可以查看TLB，TLB会直接返回物理地址，而不需要通过page table得到结果。

TLB的实现是处理器的逻辑，对操作系统来说是不可见的。就目前来说，需要知道TLB存在的唯一原因是，如果切换了page table，操作系统需要告诉处理器当前正在切换page table，处理器就会清空TLB。

另外，操作系统对于Page Table提供的映射关系具有完全的控制权，也就是说，我们可以通过操作系统操纵Page Table来完成各种各样有意思的事情。Page Table是一个无比强大的机制，它为操作系统提供了非常大的灵活性。这就是为什么page table如此流行的一个原因。

# Kernel Page

下图展示了内核中地址的对应关系，左边为内核的虚拟地址空间，右边为物理地址空间。

![内核中地址对应关系](/images/内核中地址对应关系.png)

图中右边部分的结构完全由硬件设计者决定。右边部分从0x80000000开始，为DDAM开始的位置，这也就对应了操作系统启动时，boot loader会将内核程序放到0x80000000处开始运行。0x80000000这个位置以前的是IO设备，例如：

1. PLIC是中断控制器（Platform-Level Interrupt Controller）。
2. CLINT（Core Local Interruptor）也是中断的一部分。所以多个设备都能产生中断，需要中断控制器来将这些中断路由到合适的处理函数。
3. UART0（Universal Asynchronous Receiver/Transmitter）负责与Console和显示器交互。
4. VIRTIO disk，与磁盘进行交互。

因此可以这么说，高于0x80000000的物理地址对应DRAM芯片，低于0x80000000的物理地址，不存在于DRAM中，对应IO设备。

接下来看看这张图的左边部分，这就是XV6内核的虚拟内存地址空间。当机器刚刚启动时，还没有可用的page，XV6操作系统会设置好内核使用的虚拟地址空间，也就是这张图左边的地址分布。在XV6内核中，虚拟地址到物理地址的映射大部分是相等的关系。在这里关于内核，Frans教授提到了两件重要的事情，我就直接引用Frans教授的原话了。

> 第一件事情是，有一些page在虚拟内存中的地址很靠后，比如kernel stack在虚拟内存中的地址就很靠后。这是因为在它之下有一个未被映射的Guard page，这个Guard page对应的PTE的Valid 标志位没有设置，这样，如果kernel stack耗尽了，它会溢出到Guard page，但是因为Guard page的PTE中Valid标志位未设置，会导致立即触发page fault，这样的结果好过内存越界之后造成的数据混乱。立即触发一个panic（也就是page fault），你就知道kernel stack出错了。同时我们也又不想浪费物理内存给Guard page，所以Guard page不会映射到任何物理内存，它只是占据了虚拟地址空间的一段靠后的地址。
>
> 同时，kernel stack被映射了两次，在靠后的虚拟地址映射了一次，在PHYSTOP下的Kernel data中又映射了一次，但是实际使用的时候用的是上面的部分，因为有Guard page会更加安全。这是众多你可以通过page table实现的有意思的事情之一。你可以向同一个物理地址映射两个虚拟地址，你可以不将一个虚拟地址映射到物理地址。可以是一对一的映射，一对多映射，多对一映射。XV6至少在1-2个地方用到类似的技巧。这的kernel stack和Guard page就是XV6基于page table使用的有趣技巧的一个例子。
>
> 第二件事情是权限。例如Kernel text page被标位R-X，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向Kernel text写数据。通过设置权限我们可以尽早的发现Bug从而避免Bug。对于Kernel data需要能被写入，所以它的标志位是RW-，但是你不能在这个地址段运行指令，所以它的X标志位未被设置。（注，所以，kernel text用来存代码，代码可以读，可以运行，但是不能篡改，kernel data用来存数据，数据可以读写，但是不能通过数据伪装代码在kernel中运行）

# kvminit函数

上面一节提到，当机器刚刚启动时XV6会设置内核使用的虚拟地址控制，这部分代码在 `kernel/vm.c` 中。在这个文件中，有一个 `kvmmake` 函数，这个函数会设置好kernel的地址空间。kvminit的代码如下：

```c
// Make a direct-map page table for the kernel.
pagetable_t
kvmmake(void)
{
  pagetable_t kpgtbl;

  kpgtbl = (pagetable_t) kalloc();
  memset(kpgtbl, 0, PGSIZE);

  // uart registers
  kvmmap(kpgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);

  // virtio mmio disk interface
  kvmmap(kpgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);

  // PLIC
  kvmmap(kpgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W);

  // map kernel text executable and read-only.
  kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);

  // map kernel data and the physical RAM we'll make use of.
  kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);

  // map the trampoline for trap entry/exit to
  // the highest virtual address in the kernel.
  kvmmap(kpgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);

  // map kernel stacks
  proc_mapstacks(kpgtbl);
  
  return kpgtbl;
}
```

可以看到，这个函数第一步是为最高一级page directory分配物理page，然后将这段内存初始化为0。之后，通过kvmmap函数，将每一个I/O设备映射到内核。`kernel/memlayout.h` 这个文件就将这些IO设备名翻译为了常量，例如 `memlayout.h` 的一行

```c
#define UART0 0x10000000L
```

就将UART0对应了地址0x10000000。所以，通过 `kvmmap` 函数就可以将物理地址映射到相同的虚拟地址（因为其第2、3个参数相同）。内核会持续的按照这种方式，调用 `kvmmap` 来设置地址空间。这个函数最后一个参数是设置 PTE 的标志位。
